{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test Refactored Architecture\n",
        "\n",
        "This notebook tests the new modular system design with:\n",
        "- Stage-specific processors\n",
        "- Clean data loaders  \n",
        "- Proper separation of concerns\n",
        "- Input validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "\n",
        "from flows.processing.data_loaders import RawDataLoader, SummaryDataLoader\n",
        "from flows.processing.stage_processors import summarize_item, categorize_item\n",
        "from flows.processing.tasks import get_items, process_item\n",
        "from pipeline.pipeline_state import PipelineStateManager\n",
        "from pipeline.config import pipeline_stages\n",
        "from src.utils.logging_utils import setup_logger\n",
        "\n",
        "logger = setup_logger(\"test_refactored\", \"test_refactored.log\")\n",
        "\n",
        "print(\"✓ All imports successful\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Test Data Loaders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test RawDataLoader\n",
        "raw_loader = RawDataLoader()\n",
        "\n",
        "# Find a test file\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "test_files = list(Path(\"../data/raw\").rglob(\"*.json\"))\n",
        "if test_files:\n",
        "    test_file = str(test_files[0])\n",
        "    print(f\"Testing with file: {test_file}\")\n",
        "    \n",
        "    try:\n",
        "        raw_data = raw_loader.load(test_file)\n",
        "        print(f\"✓ RawData loaded successfully:\")\n",
        "        print(f\"  - ID: {raw_data.id}\")\n",
        "        print(f\"  - Title: {raw_data.title}\")\n",
        "        print(f\"  - Type: {raw_data.type}\")\n",
        "        print(f\"  - Speakers: {raw_data.speakers}\")\n",
        "        print(f\"  - Transcript length: {len(raw_data.transcript)} chars\")\n",
        "    except Exception as e:\n",
        "        print(f\"✗ RawData loading failed: {e}\")\n",
        "else:\n",
        "    print(\"⚠ No test files found in data/raw/\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Test Stage Processors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test getting items for summarization\n",
        "try:\n",
        "    items = get_items(pipeline_stages.SUMMARIZE)\n",
        "    print(f\"✓ Found {len(items)} items ready for summarization\")\n",
        "    \n",
        "    if items:\n",
        "        item = items[0]\n",
        "        print(f\"  - Testing item: {item['id']}\")\n",
        "        print(f\"  - Raw file: {item['raw_file_path']}\")\n",
        "        \n",
        "        # Test summarization processor\n",
        "        result = summarize_item(item)\n",
        "        if result['success']:\n",
        "            print(f\"✓ Summarization successful:\")\n",
        "            print(f\"  - Summary length: {len(result['result'].summary)} chars\")\n",
        "            print(f\"  - Word count: {result['result'].summary_word_count}\")\n",
        "        else:\n",
        "            print(f\"✗ Summarization failed: {result['error']}\")\n",
        "    else:\n",
        "        print(\"⚠ No items found for summarization\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"✗ Error testing stage processors: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Test Error Handling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test error handling with invalid data\n",
        "print(\"Testing error handling...\")\n",
        "\n",
        "# Test with non-existent file\n",
        "try:\n",
        "    raw_loader.load(\"non_existent_file.json\")\n",
        "    print(\"✗ Should have failed with non-existent file\")\n",
        "except FileNotFoundError:\n",
        "    print(\"✓ Correctly handled non-existent file\")\n",
        "\n",
        "# Test with invalid item for processing\n",
        "invalid_item = {\"id\": \"test\", \"raw_file_path\": \"fake_path.json\"}\n",
        "result = process_item(invalid_item, pipeline_stages.SUMMARIZE)\n",
        "if not result['success']:\n",
        "    print(\"✓ Correctly handled invalid item processing\")\n",
        "    print(f\"  Error: {result['error']}\")\n",
        "else:\n",
        "    print(\"✗ Should have failed with invalid item\")\n",
        "\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "### ✅ **Improved System Design:**\n",
        "\n",
        "**1. Single Responsibility Principle:**\n",
        "- `RawDataLoader` → Only loads raw data\n",
        "- `SummaryDataLoader` → Only loads summary data  \n",
        "- `summarize_item` → Only handles summarization\n",
        "- `categorize_item` → Only handles categorization\n",
        "\n",
        "**2. Clean Abstractions:**\n",
        "- Data loaders use dataclasses for type safety\n",
        "- Stage processors have clear input/output contracts\n",
        "- Error handling is consistent across all components\n",
        "\n",
        "**3. Proper Validation:**\n",
        "- Required field validation in data loaders\n",
        "- Content validation in processors\n",
        "- Graceful error handling with detailed messages\n",
        "\n",
        "**4. Maintainable Architecture:**\n",
        "- Easy to add new stages (just create new processor)\n",
        "- Easy to modify data formats (just update dataclasses)\n",
        "- Clear separation between loading, processing, and orchestration\n",
        "\n",
        "**5. No More Problems:**\n",
        "- ❌ No more giant if/elif blocks\n",
        "- ❌ No more hard-coded values scattered around\n",
        "- ❌ No more mixed abstraction levels\n",
        "- ❌ No more tight coupling between components\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
