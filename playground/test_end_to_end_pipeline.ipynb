{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# End-to-End Pipeline Test\n",
        "\n",
        "Tests the complete flow:\n",
        "1. Generate test transcripts (emulate scraping)\n",
        "2. Run preprocessing (summarization)\n",
        "3. Run processing (categorization)\n",
        "4. Verify results\n",
        "\n",
        "**Note:** Each run creates NEW unique test files (timestamped).\n",
        "To clean up test data, run: `cleanup_test_data()`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "sys.path.insert(0, str(Path.cwd().parent))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Generate Test Transcripts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"STEP 1: Generate Test Transcripts\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "from tests.mock_scrape_flow import mock_scrape_flow, cleanup_test_data\n",
        "\n",
        "# Optional: Clean up old test data\n",
        "# cleanup_test_data()\n",
        "\n",
        "# Generate 3 test transcripts (creates new unique files every run)\n",
        "result = mock_scrape_flow(num_items=3)\n",
        "print(f\"✓ Generated test transcripts\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Check Pipeline State\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 2: Check Pipeline State\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "from pipeline.pipeline_state import PipelineStateManager\n",
        "\n",
        "manager = PipelineStateManager()\n",
        "\n",
        "# Get items ready for summarization\n",
        "summarize_items = manager.get_next_stage_tasks(\"summarize\")\n",
        "print(f\"Items ready for summarization: {len(summarize_items)}\")\n",
        "for item in summarize_items[:3]:\n",
        "    print(f\"  - {item.id[:8]}... | {item.raw_file_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Run Preprocessing (Summarization)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 3: Run Preprocessing (Summarization)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "from flows.preprocessing_flow import preprocessing_flow\n",
        "\n",
        "preprocessing_flow()\n",
        "print(f\"✓ Preprocessing complete\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Check Items Ready for Categorization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 4: Check Items Ready for Categorization\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "categorize_items = manager.get_next_stage_tasks(\"categorize\")\n",
        "print(f\"Items ready for categorization: {len(categorize_items)}\")\n",
        "for item in categorize_items[:3]:\n",
        "    print(f\"  - {item.id[:8]}... | Stage: {item.latest_completed_stage}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Run Processing (Categorization)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 5: Run Processing (Categorization)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "from flows.processing_flow import processing_flow\n",
        "\n",
        "processing_flow()\n",
        "print(f\"✓ Processing complete\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Verify Pipeline Completion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 6: Verify Pipeline Completion\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Check for completed items\n",
        "all_states = manager._read_all_states()\n",
        "completed = [s for s in all_states if s.get('next_stage') is None]\n",
        "print(f\"✅ Completed items: {len(completed)}\")\n",
        "\n",
        "# Show summary\n",
        "for state in completed[:3]:\n",
        "    print(f\"  - {state['id'][:8]}... | {state['latest_completed_stage']} → DONE\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"END-TO-END PIPELINE TEST COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Total items processed: {len(completed)}\")\n",
        "print(\"Pipeline stages: RAW → SUMMARIZE → CATEGORIZE → COMPLETE\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
